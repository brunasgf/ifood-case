{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r09Ge5kyHI3B"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import os\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "class TripDataDownloader:\n",
        "    \"\"\"\n",
        "    Classe responsável por baixar arquivos de dados de viagens de táxi\n",
        "    de um endpoint HTTP e salvá-los em um caminho de destino local ou em nuvem.\n",
        "\n",
        "    Parâmetros:\n",
        "    - spark: SparkSession ativa para leitura e escrita de arquivos Parquet.\n",
        "    - s3_base_path: Caminho base onde os arquivos serão gravados (pode ser local ou S3).\n",
        "    - base_url: URL base para download dos arquivos.\n",
        "    - types: Lista de tipos de táxis (ex: ['yellow', 'green']).\n",
        "    - months: Lista de meses (formato 'MM') para filtrar os arquivos.\n",
        "    - years: Lista de anos (formato 'YYYY') opcional para filtrar os arquivos.\n",
        "    \"\"\"\n",
        "    def __init__(self, spark, s3_base_path, base_url, types=None, months=None, years=None):\n",
        "        \"\"\"\n",
        "        Inicializa o downloader com parâmetros de configuração.\n",
        "\n",
        "        - spark: instância de SparkSession para operações de I/O.\n",
        "        - s3_base_path: diretório ou bucket onde os dados serão salvos.\n",
        "        - base_url: prefixo de URL para download dos arquivos de viagem.\n",
        "        - types: tipos de trips a serem baixados (default: None).\n",
        "        - months: meses a serem processados (default: None).\n",
        "        - years: anos a serem processados (default: None).\n",
        "        \"\"\"\n",
        "        self.spark = spark\n",
        "        self.s3_base_path = s3_base_path.rstrip('/')\n",
        "        self.base_url = base_url\n",
        "        self.types = types\n",
        "        self.months = months\n",
        "        self.years = years\n",
        "\n",
        "    def download_and_save(self):\n",
        "        \"\"\"\n",
        "        Para cada combinação de tipo, mês e ano configurados:\n",
        "        1. Constrói o nome do arquivo e a URL de download.\n",
        "        2. Faz requisição HTTP para obter o arquivo Parquet.\n",
        "        3. Armazena temporariamente em '/tmp'.\n",
        "        4. Lê o Parquet com Spark e escreve no destino definido.\n",
        "        5. Remove o arquivo temporário ao final.\n",
        "        \"\"\"\n",
        "        spark = SparkSession.builder.appName(\"iFoodCase\").getOrCreate()\n",
        "        for t in self.types:\n",
        "            for m in self.months:\n",
        "                filename = f\"{t}_tripdata_2023-{m}.parquet\"\n",
        "                url = self.base_url + filename\n",
        "                print(f\"Baixando {filename} de {url}...\")\n",
        "\n",
        "                try:\n",
        "                    r = requests.get(url, timeout=60)\n",
        "                    r.raise_for_status()\n",
        "\n",
        "                    local_tmp_path = f\"/tmp/{filename}\"\n",
        "                    with open(local_tmp_path, \"wb\") as f:\n",
        "                        f.write(r.content)\n",
        "\n",
        "                    df = self.spark.read.parquet(local_tmp_path)\n",
        "                    s3_output_path = f\"{self.s3_base_path}/{t}/year=2023/month={m}\"\n",
        "                    print(f\"Salvando no S3: {s3_output_path}\")\n",
        "                    df.write.mode(\"overwrite\").parquet(s3_output_path)\n",
        "\n",
        "                    os.remove(local_tmp_path)\n",
        "                    print(\" → OK\")\n",
        "\n",
        "                except requests.exceptions.HTTPError as e:\n",
        "                    print(f\"Arquivo indisponível ({e}), pulando {filename}.\")\n",
        "                except Exception as e:\n",
        "                    print(f\" Erro ao processar {filename}: {e}\")\n"
      ],
      "metadata": {
        "id": "ylzuqv13Hxl8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "gdrive_path = \"/content/drive/MyDrive/ifood/teste_2/\"\n",
        "spark = SparkSession.builder.appName(\"iFoodCase\").getOrCreate()\n",
        "\n",
        "downloader = TripDataDownloader(\n",
        "    spark=spark,\n",
        "    base_url = \"https://d37ci6vzurychx.cloudfront.net/trip-data/\",\n",
        "    s3_base_path=gdrive_path,\n",
        "    years=[2023],\n",
        "    types=['yellow', 'green', 'fhv', 'fhvhv'],\n",
        "    months=['01', '02', '03', '04', '05']\n",
        ")\n",
        "\n",
        "downloader.download_and_save()\n"
      ],
      "metadata": {
        "id": "X37AAszpH3S6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}